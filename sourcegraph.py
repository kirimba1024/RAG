"""Sourcegraph –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ–¥–æ–º —á–µ—Ä–µ–∑ GraphQL API"""

import os
from pathlib import Path

import requests

from utils import SOURCEGRAPH_URL, SOURCEGRAPH_REPO_NAME, setup_logging

logger = setup_logging(Path(__file__).stem)

GRAPHQL_ENDPOINT = f"{SOURCEGRAPH_URL}/.api/graphql"
HEADERS = {
    "Content-Type": "application/json",
    "Authorization": f"token {os.getenv('SOURCEGRAPH_TOKEN')}",
}

CHUNK_SIZE = 512

def _execute_graphql(query: str, variables: dict | None = None) -> dict:
    payload = {"query": query}
    if variables:
        payload["variables"] = variables
    resp = requests.post(GRAPHQL_ENDPOINT, json=payload, headers=HEADERS, timeout=30)
    resp.raise_for_status()
    return resp.json()

def get_file_chunks(rel_path: str) -> list[dict]:
    gql = f"""
    query FileChunks($path: String!) {{
      repository(name: "{SOURCEGRAPH_REPO_NAME}") {{
        commit(rev: "HEAD") {{
          file(path: $path) {{
            content
            binary
          }}
          blob(path: $path) {{
            symbols(first: 2000) {{
              nodes {{
                name
                kind
                location {{
                  range {{
                    start {{
                      line
                    }}
                    end {{
                      line
                    }}
                  }}
                }}
              }}
            }}
          }}
        }}
      }}
    }}
    """
    result = _execute_graphql(gql, {"path": rel_path})
    if "errors" in result:
        raise Exception(f"GraphQL –æ—à–∏–±–∫–∞: {result['errors']}")
    commit_data = result["data"]["repository"]["commit"]
    file_data = commit_data["file"]
    blob_data = commit_data.get("blob")
    if file_data.get("binary"):
        raise Exception(f"–ë–∏–Ω–∞—Ä–Ω—ã–π —Ñ–∞–π–ª {rel_path} –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è")
    content = file_data.get("content")
    if not content:
        raise Exception(f"–§–∞–π–ª {rel_path} –∏–º–µ–µ—Ç –ø—É—Å—Ç–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ")
    symbols = []
    if blob_data:
        symbols = (blob_data.get("symbols", {}) or {}).get("nodes", [])
    lines = content.split("\n")
    chunks = []
    if symbols:
        for s in symbols:
            location = s.get("location", {})
            range_data = location.get("range", {})
            start = range_data.get("start", {}).get("line")
            end = range_data.get("end", {}).get("line")
            if start and end:
                text = "\n".join(lines[start-1:end])
                if text:
                    chunks.append({
                        "start_line": start,
                        "end_line": end,
                        "kind": s.get("kind", "text"),
                        "text": text,
                    })
        if chunks:
            return chunks
    logger.warning(f"No symbols found for {rel_path}, using chunking")
    start_line = 1
    while start_line <= len(lines):
        end_line = min(start_line + CHUNK_SIZE - 1, len(lines))
        text = "\n".join(lines[start_line-1:end_line])
        chunks.append({
            "start_line": start_line,
            "end_line": end_line,
            "kind": "text",
            "text": text,
        })
        start_line = end_line + 1
    return chunks

def sg_search(query: str, path_prefix: str, limit: int) -> str:
    path_prefix = path_prefix.lstrip("/").lstrip(".")
    if path_prefix:
        search_query = f"file:{path_prefix} {query}"
    else:
        search_query = query
    gql_query = """
    query SearchResults($query: String!) {
      search(query: $query) {
        results { results { ... on FileMatch { file { path url } lineMatches { lineNumber preview } } } }
      }
    }
    """
    result = _execute_graphql(gql_query, {"query": search_query})
    if "errors" in result:
        raise Exception(f"GraphQL –æ—à–∏–±–∫–∞: {result['errors']}")
    matches = result["data"]["search"]["results"]["results"][:limit]
    if not matches:
        return f"–ü–æ–∏—Å–∫: '{query}' –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
    prefix_info = f" ({path_prefix})" if path_prefix else ""
    out = [f"üîç Sourcegraph –ø–æ–∏—Å–∫: '{query}'{prefix_info} ({len(matches)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤):\n"]
    for m in matches:
        f = m["file"]
        out.append(f"\nüìÑ {f['path']}")
        for lm in m["lineMatches"][:5]:
            out.append(f"  {lm['lineNumber']}: {lm['preview'].strip()}")
    return "\n".join(out)

def sg_codeintel(mode: str, symbol: str, path_prefix: str) -> str:
    path_prefix = path_prefix.lstrip("/").lstrip(".")
    if path_prefix:
        search_query = f"type:symbol file:{path_prefix} {symbol}"
    else:
        search_query = f"type:symbol {symbol}"
    gql_query = """
    query SymbolSearch($query: String!) {
      search(query: $query) {
        results { results { ... on FileMatch { file { path } lineMatches { lineNumber } } } }
      }
    }
    """
    result = _execute_graphql(gql_query, {"query": search_query})
    if "errors" in result:
        raise Exception(f"GraphQL –æ—à–∏–±–∫–∞: {result['errors']}")
    matches = result["data"]["search"]["results"]["results"]
    if not matches:
        return f"–°–∏–º–≤–æ–ª '{symbol}' –Ω–µ –Ω–∞–π–¥–µ–Ω"
    out = [f"üìå {'–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è' if mode == 'definitions' else '–°—Å—ã–ª–∫–∏'} —Å–∏–º–≤–æ–ª–∞ '{symbol}':\n"]
    for m in matches[:15]:
        f = m["file"]
        lines = [lm["lineNumber"] for lm in m.get("lineMatches", [])[:5]]
        line_str = f":{lines[0]}" if lines else ""
        out.append(f"  üìÑ {f['path']}{line_str}")
    return "\n".join(out)

def sg_blob(rel_path: str, start_line: int, end_line: int) -> str:
    gql_query = f"""
    query BlobContent($path: String!) {{
      repository(name: "{SOURCEGRAPH_REPO_NAME}") {{ commit(rev: "HEAD") {{ file(path: $path) {{ content binary }} }} }}
    }}
    """
    result = _execute_graphql(gql_query, {"path": rel_path})
    file_data = result["data"]["repository"]["commit"]["file"]
    if file_data["binary"]:
        return f"–§–∞–π–ª {rel_path} —è–≤–ª—è–µ—Ç—Å—è –±–∏–Ω–∞—Ä–Ω—ã–º"
    lines = file_data["content"].split("\n")
    selected = lines[start_line - 1:end_line]
    out = [f"üìÑ {rel_path} (—Å—Ç—Ä–æ–∫–∏ {start_line}-{end_line}):\n"]
    for i, line in enumerate(selected, start=start_line):
        out.append(f"{i:4d} | {line}")
    return "\n".join(out)

def sg_file_neighbors(rel_path: str, path_prefix: str, max_neighbors: int) -> str:
    path_prefix = path_prefix.lstrip("/").lstrip(".")
    gql_symbols = f"""
    query FileSymbols($path: String!) {{
      repository(name: "{SOURCEGRAPH_REPO_NAME}") {{
        commit(rev: "HEAD") {{
          blob(path: $path) {{
            symbols(first: 50) {{
              nodes {{
                name
              }}
            }}
          }}
        }}
      }}
    }}
    """
    symbols_result = _execute_graphql(gql_symbols, {"path": rel_path})
    blob_data = symbols_result["data"]["repository"]["commit"].get("blob")
    if not blob_data:
        return f"–§–∞–π–ª {rel_path} –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –±–∏–Ω–∞—Ä–Ω—ã–π"
    symbols = blob_data.get("symbols", {}).get("nodes", [])
    if not symbols:
        return f"–§–∞–π–ª {rel_path} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–∏–º–≤–æ–ª–æ–≤"
    neighbor_files = set()
    for symbol_node in symbols:
        symbol_name = symbol_node.get("name")
        if not symbol_name:
            continue
        search_query = f"type:symbol {symbol_name}" + (f" file:{path_prefix}" if path_prefix else "")
        gql_refs = """
        query SymbolRefs($query: String!) {
          search(query: $query) {
            results { results { ... on FileMatch { file { path } } } }
          }
        }
        """
        refs_result = _execute_graphql(gql_refs, {"query": search_query})
        if "errors" in refs_result:
            continue
        matches = refs_result["data"]["search"]["results"]["results"]
        for m in matches:
            file_path = m["file"]["path"]
            if file_path != rel_path:
                neighbor_files.add(file_path)
        if len(neighbor_files) >= max_neighbors:
            break
    if not neighbor_files:
        return f"–°–æ—Å–µ–¥–Ω–∏–µ —Ñ–∞–π–ª—ã –¥–ª—è {rel_path} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
    out = [f"üîó –°–æ—Å–µ–¥–Ω–∏–µ —Ñ–∞–π–ª—ã –¥–ª—è {rel_path}:\n"]
    for neighbor_path in sorted(neighbor_files)[:max_neighbors]:
        out.append(f"  üìÑ {neighbor_path}")
    return "\n".join(out)
